{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luQ1LT6CLkwp"
      },
      "outputs": [],
      "source": [
        "# Enhanced Certificate Caption Generator - Dependencies Installation\n",
        "# This cell installs all required packages for the enhanced version\n",
        "\n",
        "# Core dependencies\n",
        "!pip install torch transformers sentence-transformers\n",
        "!pip install pytesseract easyocr opencv-python-headless\n",
        "!pip install PyMuPDF pillow numpy requests\n",
        "!pip install pdf2image streamlit gradio\n",
        "!pip install python-dotenv textblob\n",
        "\n",
        "# Try to install system dependencies (works in Colab)\n",
        "try:\n",
        "    !apt-get update -qq\n",
        "    !apt-get install -y tesseract-ocr poppler-utils\n",
        "    print(\"‚úÖ System dependencies installed successfully\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Could not install system dependencies (normal for local environments)\")\n",
        "    print(\"üìã For local use, install manually:\")\n",
        "    print(\"   - Tesseract OCR: https://github.com/tesseract-ocr/tesseract\")\n",
        "    print(\"   - Poppler: https://poppler.freedesktop.org/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvPAO7tVYJge"
      },
      "outputs": [],
      "source": [
        "# Enhanced Certificate to Caption Generator - Core Implementation\n",
        "# Simplified version to avoid dependency conflicts\n",
        "\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "import tempfile\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "# Core libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# OCR libraries\n",
        "import pytesseract\n",
        "try:\n",
        "    import easyocr\n",
        "    EASYOCR_AVAILABLE = True\n",
        "    print(\"‚úÖ EasyOCR available\")\n",
        "except ImportError:\n",
        "    EASYOCR_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è EasyOCR not available - using PyTesseract only\")\n",
        "\n",
        "# PDF processing\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "\n",
        "# Simplified ML alternatives\n",
        "try:\n",
        "    from textblob import TextBlob\n",
        "    TEXTBLOB_AVAILABLE = True\n",
        "    print(\"‚úÖ TextBlob available for NLP\")\n",
        "except ImportError:\n",
        "    TEXTBLOB_AVAILABLE = False\n",
        "    print(\"‚ö†Ô∏è TextBlob not available - using basic text processing\")\n",
        "\n",
        "# Environment detection and file handling\n",
        "try:\n",
        "    from google.colab import files as colab_files\n",
        "    COLAB_ENV = True\n",
        "    print(\"üì± Running in Google Colab\")\n",
        "except ImportError:\n",
        "    COLAB_ENV = False\n",
        "    print(\"üíª Running in local environment\")\n",
        "\n",
        "try:\n",
        "    import streamlit as st\n",
        "    STREAMLIT_AVAILABLE = True\n",
        "    print(\"‚úÖ Streamlit available\")\n",
        "except ImportError:\n",
        "    STREAMLIT_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "    GRADIO_AVAILABLE = True\n",
        "    print(\"‚úÖ Gradio available\")\n",
        "except ImportError:\n",
        "    GRADIO_AVAILABLE = False\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class CertificateAnalysis:\n",
        "    \"\"\"Data class for certificate analysis results\"\"\"\n",
        "    title: str = \"\"\n",
        "    organization: str = \"\"\n",
        "    recipient_name: str = \"\"\n",
        "    completion_status: str = \"\"\n",
        "    skills_covered: List[str] = None\n",
        "    duration: str = \"\"\n",
        "    date_issued: str = \"\"\n",
        "    certificate_type: str = \"\"\n",
        "    confidence_score: float = 0.0\n",
        "    industry: str = \"\"\n",
        "    \n",
        "    def __post_init__(self):\n",
        "        if self.skills_covered is None:\n",
        "            self.skills_covered = []\n",
        "\n",
        "@dataclass\n",
        "class CaptionTemplate:\n",
        "    \"\"\"Data class for caption templates\"\"\"\n",
        "    name: str\n",
        "    style: str\n",
        "    opening: List[str]\n",
        "    achievement_templates: Dict[str, str]\n",
        "    value_statements: List[str]\n",
        "    call_to_actions: List[str]\n",
        "    hashtag_style: str\n",
        "\n",
        "class EnhancedCertificateAnalyzer:\n",
        "    \"\"\"Enhanced certificate analyzer with multiple OCR engines and advanced features\"\"\"\n",
        "    \n",
        "    def __init__(self, use_easyocr: bool = True):\n",
        "        self.use_easyocr = use_easyocr and EASYOCR_AVAILABLE\n",
        "        \n",
        "        # Initialize OCR engines\n",
        "        self.pytesseract_config = r'--oem 3 --psm 6 -l eng'\n",
        "        if self.use_easyocr:\n",
        "            try:\n",
        "                self.easyocr_reader = easyocr.Reader(['en'])\n",
        "                print(\"‚úÖ EasyOCR initialized successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå EasyOCR initialization failed: {e}\")\n",
        "                self.use_easyocr = False\n",
        "        \n",
        "        # Enhanced keywords and patterns\n",
        "        self.certificate_keywords = {\n",
        "            'completion': [\n",
        "                'completed', 'finished', 'successfully completed', 'accomplished', \n",
        "                'certified', 'graduated', 'achieved', 'earned', 'obtained',\n",
        "                'passed', 'fulfilled', 'mastered'\n",
        "            ],\n",
        "            'course_types': [\n",
        "                'course', 'training', 'program', 'workshop', 'certification',\n",
        "                'bootcamp', 'seminar', 'webinar', 'masterclass', 'diploma',\n",
        "                'degree', 'certificate', 'specialization', 'nanodegree'\n",
        "            ],\n",
        "            'organization_indicators': [\n",
        "                'organized by', 'conducted by', 'hosted by', 'presented by',\n",
        "                'issued by', 'from', 'by', 'offered by', 'provided by'\n",
        "            ],\n",
        "            'skill_indicators': [\n",
        "                'skills', 'learned', 'covered', 'topics', 'subjects', 'modules',\n",
        "                'curriculum', 'competencies', 'proficiency', 'expertise',\n",
        "                'knowledge', 'training in', 'specialization in'\n",
        "            ],\n",
        "            'duration_patterns': [\n",
        "                r'(\\d+)\\s*(hour|hr|hours|hrs)',\n",
        "                r'(\\d+)\\s*(week|weeks|wk|wks)',\n",
        "                r'(\\d+)\\s*(month|months|mon|mos)',\n",
        "                r'(\\d+)\\s*(day|days)',\n",
        "                r'(\\d+)\\s*(year|years|yr|yrs)'\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        # Industry-specific hashtag mappings\n",
        "        self.industry_hashtags = {\n",
        "            'technology': ['#TechSkills', '#Programming', '#SoftwareDevelopment', '#Innovation', '#DigitalTransformation'],\n",
        "            'data_science': ['#DataScience', '#MachineLearning', '#Analytics', '#BigData', '#AI'],\n",
        "            'design': ['#Design', '#UXDesign', '#CreativeSkills', '#VisualDesign', '#UserExperience'],\n",
        "            'business': ['#BusinessSkills', '#Leadership', '#Management', '#Strategy', '#Entrepreneurship'],\n",
        "            'marketing': ['#DigitalMarketing', '#MarketingStrategy', '#SocialMedia', '#ContentMarketing', '#SEO'],\n",
        "            'finance': ['#Finance', '#FinTech', '#Investment', '#Analysis', '#Accounting'],\n",
        "            'healthcare': ['#Healthcare', '#MedicalTraining', '#PatientCare', '#HealthTech', '#Medicine'],\n",
        "            'education': ['#Education', '#Teaching', '#LearningAndDevelopment', '#Training', '#EdTech'],\n",
        "            'general': ['#ProfessionalDevelopment', '#SkillBuilding', '#CareerGrowth', '#LearningJourney']\n",
        "        }\n",
        "        \n",
        "        # Load caption templates\n",
        "        self._load_caption_templates()\n",
        "    \n",
        "    def _load_caption_templates(self):\n",
        "        \"\"\"Load different caption style templates\"\"\"\n",
        "        self.caption_templates = {\n",
        "            'professional': CaptionTemplate(\n",
        "                name=\"Professional\",\n",
        "                style=\"formal\",\n",
        "                opening=[\"I'm pleased to share\", \"I'm proud to announce\", \"Excited to share\"],\n",
        "                achievement_templates={\n",
        "                    'course': \"I have successfully completed the {title} course{organization_text}.\",\n",
        "                    'workshop': \"I participated in the {title} workshop{organization_text}.\",\n",
        "                    'certification': \"I have earned certification in {title}{organization_text}.\"\n",
        "                },\n",
        "                value_statements=[\n",
        "                    \"This achievement strengthens my professional capabilities and expertise.\",\n",
        "                    \"The knowledge gained will be valuable in delivering exceptional results.\",\n",
        "                    \"This learning experience enhances my ability to contribute effectively to projects.\"\n",
        "                ],\n",
        "                call_to_actions=[\n",
        "                    \"Looking forward to applying these skills professionally.\",\n",
        "                    \"Ready to contribute with enhanced expertise.\",\n",
        "                    \"Excited to leverage this knowledge in future endeavors.\"\n",
        "                ],\n",
        "                hashtag_style=\"professional\"\n",
        "            ),\n",
        "            'enthusiastic': CaptionTemplate(\n",
        "                name=\"Enthusiastic\",\n",
        "                style=\"casual\",\n",
        "                opening=[\"Hey LinkedIn! üéâ\", \"Thrilled to share! üöÄ\", \"Amazing news! ‚ú®\"],\n",
        "                achievement_templates={\n",
        "                    'course': \"üéì Just crushed the {title} course{organization_text}! üí™\",\n",
        "                    'workshop': \"üéØ Had an incredible time at the {title} workshop{organization_text}! üî•\",\n",
        "                    'certification': \"üèÜ Officially certified in {title}{organization_text}! üéä\"\n",
        "                },\n",
        "                value_statements=[\n",
        "                    \"This journey has been absolutely transformative! üåü\",\n",
        "                    \"Can't wait to put these amazing skills to work! üí°\",\n",
        "                    \"Feeling more confident and ready to tackle new challenges! üí™\"\n",
        "                ],\n",
        "                call_to_actions=[\n",
        "                    \"Bring on the exciting projects! üöÄ\",\n",
        "                    \"Ready to make some magic happen! ‚ú®\",\n",
        "                    \"Let's connect and create something awesome! ü§ù\"\n",
        "                ],\n",
        "                hashtag_style=\"enthusiastic\"\n",
        "            ),\n",
        "            'technical': CaptionTemplate(\n",
        "                name=\"Technical\",\n",
        "                style=\"detailed\",\n",
        "                opening=[\"Technical milestone achieved\", \"Completed advanced training in\", \"Enhanced technical proficiency in\"],\n",
        "                achievement_templates={\n",
        "                    'course': \"Successfully completed comprehensive training in {title}{organization_text}.\",\n",
        "                    'workshop': \"Participated in intensive {title} workshop{organization_text}.\",\n",
        "                    'certification': \"Achieved professional certification in {title}{organization_text}.\"\n",
        "                },\n",
        "                value_statements=[\n",
        "                    \"This training provides practical skills directly applicable to complex technical challenges.\",\n",
        "                    \"The curriculum covered industry best practices and cutting-edge methodologies.\",\n",
        "                    \"Gained hands-on experience with tools and frameworks essential for modern development.\"\n",
        "                ],\n",
        "                call_to_actions=[\n",
        "                    \"Ready to implement these methodologies in real-world projects.\",\n",
        "                    \"Excited to contribute to technically challenging initiatives.\",\n",
        "                    \"Looking forward to collaborating on innovative solutions.\"\n",
        "                ],\n",
        "                hashtag_style=\"technical\"\n",
        "            )\n",
        "        }\n",
        "    \n",
        "    def enhance_image(self, image: Image.Image) -> Image.Image:\n",
        "        \"\"\"Enhanced image preprocessing for better OCR results\"\"\"\n",
        "        try:\n",
        "            # Convert to numpy array\n",
        "            img_array = np.array(image)\n",
        "            \n",
        "            # Convert to grayscale if not already\n",
        "            if len(img_array.shape) == 3:\n",
        "                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "            else:\n",
        "                gray = img_array\n",
        "            \n",
        "            # Apply noise reduction\n",
        "            denoised = cv2.fastNlMeansDenoising(gray)\n",
        "            \n",
        "            # Enhance contrast\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "            enhanced = clahe.apply(denoised)\n",
        "            \n",
        "            # Apply sharpening\n",
        "            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "            sharpened = cv2.filter2D(enhanced, -1, kernel)\n",
        "            \n",
        "            # Convert back to PIL Image\n",
        "            return Image.fromarray(sharpened)\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Image enhancement failed: {e}\")\n",
        "            return image\n",
        "    \n",
        "    def extract_text_pytesseract(self, image: Image.Image) -> Tuple[str, float]:\n",
        "        \"\"\"Extract text using PyTesseract with confidence scoring\"\"\"\n",
        "        try:\n",
        "            enhanced_image = self.enhance_image(image)\n",
        "            \n",
        "            # Get text with confidence data\n",
        "            data = pytesseract.image_to_data(enhanced_image, config=self.pytesseract_config, output_type=pytesseract.Output.DICT)\n",
        "            \n",
        "            # Filter confident text\n",
        "            confidences = [int(conf) for conf in data['conf'] if int(conf) > 30]\n",
        "            texts = [data['text'][i] for i, conf in enumerate(data['conf']) if int(conf) > 30 and data['text'][i].strip()]\n",
        "            \n",
        "            text = ' '.join(texts)\n",
        "            avg_confidence = np.mean(confidences) if confidences else 0\n",
        "            \n",
        "            return text, avg_confidence / 100.0\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"PyTesseract extraction failed: {e}\")\n",
        "            return \"\", 0.0\n",
        "    \n",
        "    def extract_text_easyocr(self, image: Image.Image) -> Tuple[str, float]:\n",
        "        \"\"\"Extract text using EasyOCR with confidence scoring\"\"\"\n",
        "        if not self.use_easyocr:\n",
        "            return \"\", 0.0\n",
        "        \n",
        "        try:\n",
        "            enhanced_image = self.enhance_image(image)\n",
        "            img_array = np.array(enhanced_image)\n",
        "            \n",
        "            results = self.easyocr_reader.readtext(img_array, detail=1, paragraph=True)\n",
        "            \n",
        "            texts = []\n",
        "            confidences = []\n",
        "            \n",
        "            for (bbox, text, confidence) in results:\n",
        "                if confidence > 0.3:  # Filter low confidence results\n",
        "                    texts.append(text)\n",
        "                    confidences.append(confidence)\n",
        "            \n",
        "            combined_text = ' '.join(texts)\n",
        "            avg_confidence = np.mean(confidences) if confidences else 0\n",
        "            \n",
        "            return combined_text, avg_confidence\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"EasyOCR extraction failed: {e}\")\n",
        "            return \"\", 0.0\n",
        "    \n",
        "    def extract_text_from_image(self, image_path: str) -> Dict:\n",
        "        \"\"\"Extract text from image using multiple OCR engines\"\"\"\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "            results = {}\n",
        "            \n",
        "            # Try PyTesseract\n",
        "            pytesseract_text, pytesseract_conf = self.extract_text_pytesseract(image)\n",
        "            results['pytesseract'] = {'text': pytesseract_text, 'confidence': pytesseract_conf}\n",
        "            \n",
        "            # Try EasyOCR if available\n",
        "            if self.use_easyocr:\n",
        "                easyocr_text, easyocr_conf = self.extract_text_easyocr(image)\n",
        "                results['easyocr'] = {'text': easyocr_text, 'confidence': easyocr_conf}\n",
        "            \n",
        "            # Choose best result\n",
        "            best_engine = 'pytesseract'\n",
        "            best_confidence = pytesseract_conf\n",
        "            \n",
        "            if self.use_easyocr and easyocr_conf > pytesseract_conf:\n",
        "                best_engine = 'easyocr'\n",
        "                best_confidence = easyocr_conf\n",
        "            \n",
        "            return {\n",
        "                'text': results[best_engine]['text'],\n",
        "                'confidence': best_confidence,\n",
        "                'engine_used': best_engine,\n",
        "                'all_results': results\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Image text extraction failed: {e}\")\n",
        "            return {'text': '', 'confidence': 0.0, 'engine_used': 'none', 'all_results': {}}\n",
        "    \n",
        "    def extract_text_from_pdf(self, pdf_path: str) -> Dict:\n",
        "        \"\"\"Extract text from PDF using multiple methods\"\"\"\n",
        "        try:\n",
        "            # First try direct text extraction\n",
        "            doc = fitz.open(pdf_path)\n",
        "            direct_text = \"\"\n",
        "            for page in doc:\n",
        "                direct_text += page.get_text() + \"\\n\"\n",
        "            doc.close()\n",
        "            \n",
        "            if direct_text.strip():\n",
        "                return {\n",
        "                    'text': direct_text,\n",
        "                    'confidence': 0.95,\n",
        "                    'method': 'direct_extraction',\n",
        "                    'all_results': {'direct': direct_text}\n",
        "                }\n",
        "            \n",
        "            # If no direct text, use OCR on converted images\n",
        "            logger.info(\"No direct text found, using OCR on PDF pages...\")\n",
        "            \n",
        "            try:\n",
        "                images = convert_from_path(pdf_path, dpi=300)\n",
        "            except Exception:\n",
        "                # Fallback to bytes conversion\n",
        "                with open(pdf_path, 'rb') as f:\n",
        "                    images = convert_from_bytes(f.read(), dpi=300)\n",
        "            \n",
        "            all_text = \"\"\n",
        "            confidences = []\n",
        "            \n",
        "            for i, image in enumerate(images):\n",
        "                temp_path = f\"/tmp/page_{i}.png\" if os.path.exists('/tmp') else f\"page_{i}.png\"\n",
        "                image.save(temp_path)\n",
        "                \n",
        "                result = self.extract_text_from_image(temp_path)\n",
        "                all_text += result['text'] + \"\\n\"\n",
        "                confidences.append(result['confidence'])\n",
        "                \n",
        "                # Clean up\n",
        "                try:\n",
        "                    os.remove(temp_path)\n",
        "                except:\n",
        "                    pass\n",
        "            \n",
        "            avg_confidence = np.mean(confidences) if confidences else 0\n",
        "            \n",
        "            return {\n",
        "                'text': all_text,\n",
        "                'confidence': avg_confidence,\n",
        "                'method': 'ocr_extraction',\n",
        "                'pages_processed': len(images)\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"PDF text extraction failed: {e}\")\n",
        "            return {'text': '', 'confidence': 0.0, 'method': 'failed', 'error': str(e)}\n",
        "    \n",
        "    def detect_industry(self, text: str) -> str:\n",
        "        \"\"\"Detect industry based on certificate content\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        \n",
        "        industry_keywords = {\n",
        "            'technology': ['programming', 'coding', 'software', 'development', 'python', 'java', 'javascript', 'web', 'app', 'tech', 'computer', 'it'],\n",
        "            'data_science': ['data science', 'machine learning', 'analytics', 'statistics', 'data analysis', 'ai', 'artificial intelligence', 'big data'],\n",
        "            'design': ['design', 'ux', 'ui', 'graphic', 'creative', 'photoshop', 'illustrator', 'figma', 'visual'],\n",
        "            'business': ['business', 'management', 'leadership', 'strategy', 'mba', 'entrepreneurship', 'project management'],\n",
        "            'marketing': ['marketing', 'digital marketing', 'social media', 'seo', 'content', 'advertising', 'brand'],\n",
        "            'finance': ['finance', 'financial', 'accounting', 'investment', 'banking', 'economics', 'fintech'],\n",
        "            'healthcare': ['healthcare', 'medical', 'nursing', 'health', 'clinical', 'patient', 'medicine'],\n",
        "            'education': ['education', 'teaching', 'pedagogy', 'curriculum', 'learning', 'instruction']\n",
        "        }\n",
        "        \n",
        "        scores = {}\n",
        "        for industry, keywords in industry_keywords.items():\n",
        "            score = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "            scores[industry] = score\n",
        "        \n",
        "        # Return industry with highest score, or 'general' if no clear match\n",
        "        best_industry = max(scores, key=scores.get) if max(scores.values()) > 0 else 'general'\n",
        "        return best_industry\n",
        "    \n",
        "    def analyze_certificate_content(self, text: str, confidence: float) -> CertificateAnalysis:\n",
        "        \"\"\"Enhanced certificate content analysis\"\"\"\n",
        "        analysis = CertificateAnalysis()\n",
        "        analysis.confidence_score = confidence\n",
        "        \n",
        "        if not text.strip():\n",
        "            return analysis\n",
        "        \n",
        "        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
        "        text_lower = text.lower()\n",
        "        \n",
        "        # Detect industry\n",
        "        analysis.industry = self.detect_industry(text)\n",
        "        \n",
        "        # Extract title with improved logic\n",
        "        analysis.title = self._extract_title(lines, text)\n",
        "        \n",
        "        # Extract organization\n",
        "        analysis.organization = self._extract_organization(lines, text)\n",
        "        \n",
        "        # Extract recipient name\n",
        "        analysis.recipient_name = self._extract_recipient_name(lines)\n",
        "        \n",
        "        # Extract completion status\n",
        "        analysis.completion_status = self._extract_completion_status(text_lower)\n",
        "        \n",
        "        # Determine certificate type\n",
        "        analysis.certificate_type = self._determine_certificate_type(text_lower)\n",
        "        \n",
        "        # Extract skills\n",
        "        analysis.skills_covered = self._extract_skills_advanced(text)\n",
        "        \n",
        "        # Extract duration\n",
        "        analysis.duration = self._extract_duration(text)\n",
        "        \n",
        "        # Extract date\n",
        "        analysis.date_issued = self._extract_date(text)\n",
        "        \n",
        "        return analysis\n",
        "    \n",
        "    def _extract_title(self, lines: List[str], text: str) -> str:\n",
        "        \"\"\"Enhanced title extraction\"\"\"\n",
        "        # Look for lines that are likely titles\n",
        "        title_candidates = []\n",
        "        \n",
        "        for i, line in enumerate(lines):\n",
        "            # Skip very short lines and common phrases\n",
        "            if len(line) < 10:\n",
        "                continue\n",
        "                \n",
        "            line_lower = line.lower()\n",
        "            skip_phrases = ['certificate', 'awarded', 'this', 'presented', 'completion', 'successful', 'congratulations']\n",
        "            \n",
        "            if any(phrase in line_lower for phrase in skip_phrases):\n",
        "                continue\n",
        "            \n",
        "            # Look for lines that might be titles\n",
        "            if len(line) > 15 and len(line) < 100:\n",
        "                # Give higher score to lines with title-like characteristics\n",
        "                score = 0\n",
        "                if line.isupper() or line.istitle():\n",
        "                    score += 2\n",
        "                if '\"' in line or \"'\" in line:\n",
        "                    score += 2\n",
        "                if any(word in line_lower for word in ['course', 'program', 'certification', 'training']):\n",
        "                    score += 1\n",
        "                \n",
        "                title_candidates.append((line, score, i))\n",
        "        \n",
        "        # Sort by score and position (prefer higher scores and earlier positions)\n",
        "        title_candidates.sort(key=lambda x: (-x[1], x[2]))\n",
        "        \n",
        "        return title_candidates[0][0] if title_candidates else \"Professional Development Program\"\n",
        "    \n",
        "    def _extract_organization(self, lines: List[str], text: str) -> str:\n",
        "        \"\"\"Enhanced organization extraction\"\"\"\n",
        "        org_patterns = [\n",
        "            r'(?:issued by|offered by|presented by|from)\\s+([^\\\\n]+)',\n",
        "            r'([A-Z][a-zA-Z\\s&,]+(?:University|Institute|College|Academy|Foundation|Company|Inc|LLC|Ltd|Corporation))',\n",
        "            r'((?:[A-Z][a-z]+\\s+){1,3}(?:University|Institute|College|Academy|School))'\n",
        "        ]\n",
        "        \n",
        "        for pattern in org_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return matches[0].strip()\n",
        "        \n",
        "        return \"\"\n",
        "    \n",
        "    def _extract_recipient_name(self, lines: List[str]) -> str:\n",
        "        \"\"\"Extract recipient name\"\"\"\n",
        "        for i, line in enumerate(lines):\n",
        "            line_lower = line.lower()\n",
        "            if any(phrase in line_lower for phrase in ['this certifies', 'awarded to', 'presented to', 'hereby certifies']):\n",
        "                if i + 1 < len(lines):\n",
        "                    potential_name = lines[i + 1].strip()\n",
        "                    # Basic name validation\n",
        "                    if len(potential_name.split()) >= 2 and potential_name.replace(' ', '').isalpha():\n",
        "                        return potential_name\n",
        "        return \"\"\n",
        "    \n",
        "    def _extract_completion_status(self, text_lower: str) -> str:\n",
        "        \"\"\"Extract completion status\"\"\"\n",
        "        for keyword in self.certificate_keywords['completion']:\n",
        "            if keyword in text_lower:\n",
        "                return 'completed'\n",
        "        return 'participated'\n",
        "    \n",
        "    def _determine_certificate_type(self, text_lower: str) -> str:\n",
        "        \"\"\"Determine certificate type\"\"\"\n",
        "        if any(word in text_lower for word in ['workshop', 'seminar', 'webinar']):\n",
        "            return 'workshop'\n",
        "        elif any(word in text_lower for word in ['course', 'training', 'program']):\n",
        "            return 'course'\n",
        "        elif any(word in text_lower for word in ['certification', 'certified', 'certificate']):\n",
        "            return 'certification'\n",
        "        else:\n",
        "            return 'course'\n",
        "    \n",
        "    def _extract_skills_advanced(self, text: str) -> List[str]:\n",
        "        \"\"\"Advanced skills extraction using basic NLP\"\"\"\n",
        "        skills = set()\n",
        "        \n",
        "        # Use TextBlob for noun phrase extraction if available\n",
        "        if TEXTBLOB_AVAILABLE:\n",
        "            try:\n",
        "                blob = TextBlob(text)\n",
        "                noun_phrases = blob.noun_phrases\n",
        "                \n",
        "                # Filter relevant noun phrases\n",
        "                for phrase in noun_phrases:\n",
        "                    phrase_clean = phrase.lower().strip()\n",
        "                    if len(phrase_clean.split()) <= 3 and len(phrase_clean) > 3:\n",
        "                        # Check if it looks like a skill\n",
        "                        if not any(stop_word in phrase_clean for stop_word in ['the', 'this', 'that', 'with', 'from']):\n",
        "                            skills.add(phrase_clean.title())\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        # Traditional keyword-based extraction\n",
        "        skill_patterns = [\n",
        "            r'(?:including|covering|topics:|subjects:|modules:)\\s*([^.]+)',\n",
        "            r'(?:skills in|proficiency in|training in)\\s+([^.]+)',\n",
        "            r'(?:learn|learned|learning)\\s+([^.]+)'\n",
        "        ]\n",
        "        \n",
        "        for pattern in skill_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            for match in matches:\n",
        "                # Split and clean skills\n",
        "                potential_skills = re.split(r'[,;&]', match)\n",
        "                for skill in potential_skills:\n",
        "                    skill_clean = skill.strip().title()\n",
        "                    if len(skill_clean) > 3 and len(skill_clean) < 30:\n",
        "                        skills.add(skill_clean)\n",
        "        \n",
        "        return list(skills)[:8]  # Limit to 8 skills\n",
        "    \n",
        "    def _extract_duration(self, text: str) -> str:\n",
        "        \"\"\"Extract duration information\"\"\"\n",
        "        for pattern in self.certificate_keywords['duration_patterns']:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return f\"{matches[0][0]} {matches[0][1]}\"\n",
        "        return \"\"\n",
        "    \n",
        "    def _extract_date(self, text: str) -> str:\n",
        "        \"\"\"Extract issue date\"\"\"\n",
        "        date_patterns = [\n",
        "            r'(\\d{1,2}[/-]\\d{1,2}[/-]\\d{4})',\n",
        "            r'(\\d{4}[/-]\\d{1,2}[/-]\\d{1,2})',\n",
        "            r'((?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2},?\\s+\\d{4})',\n",
        "            r'(\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{4})'\n",
        "        ]\n",
        "        \n",
        "        for pattern in date_patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            if matches:\n",
        "                return matches[0]\n",
        "        return \"\"\n",
        "\n",
        "# Initialize the enhanced analyzer\n",
        "print(\"üöÄ Initializing Enhanced Certificate Analyzer...\")\n",
        "analyzer = EnhancedCertificateAnalyzer(use_easyocr=EASYOCR_AVAILABLE)\n",
        "print(\"‚úÖ Enhanced Certificate Analyzer ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced Caption Generation System\n",
        "class CaptionGenerator:\n",
        "    \"\"\"Advanced caption generator with multiple styles and platforms\"\"\"\n",
        "    \n",
        "    def __init__(self, analyzer: EnhancedCertificateAnalyzer):\n",
        "        self.analyzer = analyzer\n",
        "        self.templates = analyzer.caption_templates\n",
        "    \n",
        "    def generate_hashtags(self, analysis: CertificateAnalysis, platform: str = \"linkedin\", max_hashtags: int = 10) -> List[str]:\n",
        "        \"\"\"Generate relevant hashtags based on analysis and platform\"\"\"\n",
        "        hashtags = set()\n",
        "        \n",
        "        # Add industry-specific hashtags\n",
        "        industry_tags = self.analyzer.industry_hashtags.get(analysis.industry, self.analyzer.industry_hashtags['general'])\n",
        "        hashtags.update(industry_tags[:3])\n",
        "        \n",
        "        # Add title-based hashtags\n",
        "        title_words = re.findall(r'\\b[A-Z][a-z]+\\b', analysis.title)\n",
        "        for word in title_words[:2]:\n",
        "            if len(word) > 3:\n",
        "                hashtags.add(f\"#{word.replace(' ', '')}\")\n",
        "        \n",
        "        # Add type-based hashtags\n",
        "        if analysis.certificate_type == 'course':\n",
        "            hashtags.update([\"#OnlineLearning\", \"#ProfessionalDevelopment\", \"#SkillsUpgrade\"])\n",
        "        elif analysis.certificate_type == 'workshop':\n",
        "            hashtags.update([\"#Workshop\", \"#HandsOnLearning\", \"#PracticalSkills\"])\n",
        "        elif analysis.certificate_type == 'certification':\n",
        "            hashtags.update([\"#Certification\", \"#ProfessionalCertification\", \"#Achievement\"])\n",
        "        \n",
        "        # Add skill-based hashtags\n",
        "        for skill in analysis.skills_covered[:2]:\n",
        "            clean_skill = re.sub(r'[^a-zA-Z0-9]', '', skill)\n",
        "            if len(clean_skill) > 3:\n",
        "                hashtags.add(f\"#{clean_skill}\")\n",
        "        \n",
        "        # Platform-specific adjustments\n",
        "        if platform == \"twitter\":\n",
        "            # Twitter has character limits, use shorter hashtags\n",
        "            hashtags = {tag for tag in hashtags if len(tag) < 20}\n",
        "            max_hashtags = min(max_hashtags, 5)\n",
        "        elif platform == \"instagram\":\n",
        "            # Instagram allows more hashtags\n",
        "            hashtags.update([\"#learning\", \"#growth\", \"#success\", \"#motivation\"])\n",
        "            max_hashtags = min(max_hashtags, 20)\n",
        "        \n",
        "        return list(hashtags)[:max_hashtags]\n",
        "    \n",
        "    def generate_caption(self, analysis: CertificateAnalysis, style: str = \"professional\", \n",
        "                        platform: str = \"linkedin\", include_skills: bool = True,\n",
        "                        custom_message: str = \"\") -> str:\n",
        "        \"\"\"Generate platform-specific captions\"\"\"\n",
        "        \n",
        "        if platform == \"linkedin\":\n",
        "            return self._generate_linkedin_caption(analysis, style, include_skills, custom_message)\n",
        "        elif platform == \"twitter\":\n",
        "            return self._generate_twitter_caption(analysis, style, include_skills)\n",
        "        elif platform == \"instagram\":\n",
        "            return self._generate_instagram_caption(analysis, style, include_skills)\n",
        "        elif platform == \"portfolio\":\n",
        "            return self._generate_portfolio_description(analysis, include_skills)\n",
        "        else:\n",
        "            return self._generate_linkedin_caption(analysis, style, include_skills, custom_message)\n",
        "    \n",
        "    def _generate_linkedin_caption(self, analysis: CertificateAnalysis, style: str, \n",
        "                                 include_skills: bool, custom_message: str) -> str:\n",
        "        \"\"\"Generate LinkedIn-optimized caption\"\"\"\n",
        "        template = self.templates.get(style, self.templates['professional'])\n",
        "        caption_parts = []\n",
        "        \n",
        "        # Opening\n",
        "        if custom_message:\n",
        "            caption_parts.append(custom_message)\n",
        "        else:\n",
        "            opening = np.random.choice(template.opening)\n",
        "            caption_parts.append(f\"{opening} üéâ\")\n",
        "        \n",
        "        caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Achievement statement\n",
        "        org_text = f\" from {analysis.organization}\" if analysis.organization else \"\"\n",
        "        achievement_template = template.achievement_templates.get(analysis.certificate_type, \n",
        "                                                                template.achievement_templates['course'])\n",
        "        achievement = achievement_template.format(title=analysis.title, organization_text=org_text)\n",
        "        caption_parts.append(achievement)\n",
        "        caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Skills section\n",
        "        if include_skills and analysis.skills_covered:\n",
        "            skills_text = \", \".join(analysis.skills_covered[:4])\n",
        "            if style == \"professional\":\n",
        "                skills_section = f\"üìö Key areas covered: {skills_text}\"\n",
        "            elif style == \"enthusiastic\":\n",
        "                skills_section = f\"üí° Dove deep into: {skills_text} - mind blown! ü§Ø\"\n",
        "            else:\n",
        "                skills_section = f\"üîß Technical competencies gained: {skills_text}\"\n",
        "            \n",
        "            caption_parts.append(skills_section)\n",
        "            caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Duration if available\n",
        "        if analysis.duration:\n",
        "            caption_parts.append(f\"‚è±Ô∏è Duration: {analysis.duration}\")\n",
        "            caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Value statement\n",
        "        value_statement = np.random.choice(template.value_statements)\n",
        "        caption_parts.append(value_statement)\n",
        "        caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Call to action\n",
        "        cta = np.random.choice(template.call_to_actions)\n",
        "        caption_parts.append(cta)\n",
        "        caption_parts.append(\"\\n\\n\")\n",
        "        \n",
        "        # Hashtags\n",
        "        hashtags = self.generate_hashtags(analysis, \"linkedin\")\n",
        "        caption_parts.append(\" \".join(hashtags))\n",
        "        \n",
        "        return \"\".join(caption_parts)\n",
        "    \n",
        "    def _generate_twitter_caption(self, analysis: CertificateAnalysis, style: str, include_skills: bool) -> str:\n",
        "        \"\"\"Generate Twitter-optimized caption (character limit conscious)\"\"\"\n",
        "        parts = []\n",
        "        \n",
        "        if style == \"enthusiastic\":\n",
        "            parts.append(f\"üéâ Just completed {analysis.title}!\")\n",
        "        else:\n",
        "            parts.append(f\"‚úÖ Completed: {analysis.title}\")\n",
        "        \n",
        "        if analysis.organization:\n",
        "            org_short = analysis.organization.split()[0] if len(analysis.organization) > 20 else analysis.organization\n",
        "            parts.append(f\" @{org_short}\")\n",
        "        \n",
        "        if include_skills and analysis.skills_covered:\n",
        "            skills_short = \", \".join(analysis.skills_covered[:2])\n",
        "            parts.append(f\"\\nüîß {skills_short}\")\n",
        "        \n",
        "        parts.append(\"\\nüí™ Ready for new challenges!\")\n",
        "        \n",
        "        # Add hashtags (Twitter limit)\n",
        "        hashtags = self.generate_hashtags(analysis, \"twitter\", max_hashtags=3)\n",
        "        parts.append(f\"\\n{' '.join(hashtags)}\")\n",
        "        \n",
        "        caption = \"\".join(parts)\n",
        "        \n",
        "        # Ensure under 280 characters\n",
        "        if len(caption) > 280:\n",
        "            caption = caption[:277] + \"...\"\n",
        "        \n",
        "        return caption\n",
        "    \n",
        "    def _generate_instagram_caption(self, analysis: CertificateAnalysis, style: str, include_skills: bool) -> str:\n",
        "        \"\"\"Generate Instagram-optimized caption\"\"\"\n",
        "        parts = []\n",
        "        \n",
        "        # Instagram loves emojis and stories\n",
        "        parts.append(\"‚ú® NEW ACHIEVEMENT UNLOCKED ‚ú®\\n\\n\")\n",
        "        \n",
        "        if style == \"enthusiastic\":\n",
        "            parts.append(f\"üöÄ Just crushed the {analysis.title} course! \")\n",
        "        else:\n",
        "            parts.append(f\"üéì Successfully completed {analysis.title}. \")\n",
        "        \n",
        "        if analysis.organization:\n",
        "            parts.append(f\"Huge thanks to {analysis.organization}! üôè\\n\\n\")\n",
        "        \n",
        "        if include_skills and analysis.skills_covered:\n",
        "            parts.append(\"üí° What I learned:\\n\")\n",
        "            for skill in analysis.skills_covered[:3]:\n",
        "                parts.append(f\"‚Ä¢ {skill}\\n\")\n",
        "            parts.append(\"\\n\")\n",
        "        \n",
        "        parts.append(\"This journey has been incredible! üí™ Can't wait to apply these new skills. \")\n",
        "        parts.append(\"What's your latest learning achievement? Drop it in the comments! üëá\\n\\n\")\n",
        "        \n",
        "        # Instagram allows many hashtags\n",
        "        hashtags = self.generate_hashtags(analysis, \"instagram\", max_hashtags=15)\n",
        "        parts.append(\" \".join(hashtags))\n",
        "        parts.append(\"\\n\\n#learning #growth #education #skills #achievement #motivation #success\")\n",
        "        \n",
        "        return \"\".join(parts)\n",
        "    \n",
        "    def _generate_portfolio_description(self, analysis: CertificateAnalysis, include_skills: bool) -> str:\n",
        "        \"\"\"Generate professional portfolio description\"\"\"\n",
        "        parts = []\n",
        "        \n",
        "        parts.append(f\"**{analysis.title}**\\n\")\n",
        "        \n",
        "        if analysis.organization:\n",
        "            parts.append(f\"*{analysis.organization}*\\n\")\n",
        "        \n",
        "        if analysis.date_issued:\n",
        "            parts.append(f\"Completed: {analysis.date_issued}\\n\")\n",
        "        elif analysis.duration:\n",
        "            parts.append(f\"Duration: {analysis.duration}\\n\")\n",
        "        \n",
        "        parts.append(\"\\n\")\n",
        "        \n",
        "        if include_skills and analysis.skills_covered:\n",
        "            parts.append(\"**Key Competencies:**\\n\")\n",
        "            for skill in analysis.skills_covered:\n",
        "                parts.append(f\"‚Ä¢ {skill}\\n\")\n",
        "            parts.append(\"\\n\")\n",
        "        \n",
        "        parts.append(\"This professional development program enhanced my expertise and provided \")\n",
        "        parts.append(\"practical knowledge applicable to real-world challenges. The comprehensive \")\n",
        "        parts.append(\"curriculum covered industry best practices and modern methodologies.\")\n",
        "        \n",
        "        return \"\".join(parts)\n",
        "\n",
        "# Enhanced File Processing Functions\n",
        "class FileProcessor:\n",
        "    \"\"\"Handle multiple file input methods and environments\"\"\"\n",
        "    \n",
        "    def __init__(self, analyzer: EnhancedCertificateAnalyzer):\n",
        "        self.analyzer = analyzer\n",
        "    \n",
        "    def process_file(self, file_input: Union[str, bytes], filename: str = \"\") -> Dict:\n",
        "        \"\"\"Process file from various input types\"\"\"\n",
        "        try:\n",
        "            # Determine file type and create temporary file\n",
        "            temp_path = self._prepare_temp_file(file_input, filename)\n",
        "            \n",
        "            if not temp_path:\n",
        "                return {'error': 'Could not process file input'}\n",
        "            \n",
        "            # Extract text based on file type\n",
        "            if temp_path.lower().endswith('.pdf'):\n",
        "                result = self.analyzer.extract_text_from_pdf(temp_path)\n",
        "            else:\n",
        "                result = self.analyzer.extract_text_from_image(temp_path)\n",
        "            \n",
        "            # Clean up temp file\n",
        "            self._cleanup_temp_file(temp_path)\n",
        "            \n",
        "            if result['text'].strip():\n",
        "                # Analyze content\n",
        "                analysis = self.analyzer.analyze_certificate_content(result['text'], result['confidence'])\n",
        "                return {\n",
        "                    'success': True,\n",
        "                    'analysis': analysis,\n",
        "                    'extraction_info': result,\n",
        "                    'raw_text': result['text']\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    'error': 'No text could be extracted from the file. Please ensure the image is clear and contains readable text.',\n",
        "                    'extraction_info': result\n",
        "                }\n",
        "                \n",
        "        except Exception as e:\n",
        "            logger.error(f\"File processing error: {e}\")\n",
        "            return {'error': f'File processing failed: {str(e)}'}\n",
        "    \n",
        "    def _prepare_temp_file(self, file_input: Union[str, bytes], filename: str) -> Optional[str]:\n",
        "        \"\"\"Prepare temporary file from various input types\"\"\"\n",
        "        try:\n",
        "            if isinstance(file_input, str):\n",
        "                # File path or URL\n",
        "                if file_input.startswith(('http://', 'https://')):\n",
        "                    return self._download_file(file_input, filename)\n",
        "                else:\n",
        "                    return file_input if os.path.exists(file_input) else None\n",
        "            \n",
        "            elif isinstance(file_input, bytes):\n",
        "                # Bytes data\n",
        "                temp_dir = tempfile.gettempdir()\n",
        "                temp_filename = filename or f\"temp_cert_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "                temp_path = os.path.join(temp_dir, temp_filename)\n",
        "                \n",
        "                with open(temp_path, 'wb') as f:\n",
        "                    f.write(file_input)\n",
        "                \n",
        "                return temp_path\n",
        "            \n",
        "            return None\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Temp file preparation failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _download_file(self, url: str, filename: str) -> Optional[str]:\n",
        "        \"\"\"Download file from URL\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, stream=True, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            temp_dir = tempfile.gettempdir()\n",
        "            temp_filename = filename or f\"downloaded_cert_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "            temp_path = os.path.join(temp_dir, temp_filename)\n",
        "            \n",
        "            with open(temp_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            \n",
        "            return temp_path\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"File download failed: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _cleanup_temp_file(self, file_path: str):\n",
        "        \"\"\"Clean up temporary files\"\"\"\n",
        "        try:\n",
        "            if file_path and os.path.exists(file_path) and '/tmp/' in file_path:\n",
        "                os.remove(file_path)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Initialize components\n",
        "caption_generator = CaptionGenerator(analyzer)\n",
        "file_processor = FileProcessor(analyzer)\n",
        "\n",
        "print(\"‚úÖ Enhanced caption generation system ready!\")\n",
        "print(\"üéØ Features available:\")\n",
        "print(\"   ‚Ä¢ Multiple OCR engines (PyTesseract + EasyOCR)\")\n",
        "print(\"   ‚Ä¢ Advanced image preprocessing\")\n",
        "print(\"   ‚Ä¢ Multiple caption styles (Professional, Enthusiastic, Technical)\")\n",
        "print(\"   ‚Ä¢ Multi-platform support (LinkedIn, Twitter, Instagram, Portfolio)\")\n",
        "print(\"   ‚Ä¢ Industry-specific hashtags\")\n",
        "print(\"   ‚Ä¢ URL and local file support\")\n",
        "print(\"   ‚Ä¢ Enhanced error handling\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multi-Platform User Interface Functions\n",
        "\n",
        "def process_certificate_advanced(file_input: Union[str, bytes], \n",
        "                                filename: str = \"\",\n",
        "                                style: str = \"professional\",\n",
        "                                platform: str = \"linkedin\",\n",
        "                                include_skills: bool = True,\n",
        "                                custom_message: str = \"\") -> Dict:\n",
        "    \"\"\"\n",
        "    Advanced certificate processing with multiple options\n",
        "    \n",
        "    Args:\n",
        "        file_input: File path, URL, or bytes data\n",
        "        filename: Optional filename for bytes input\n",
        "        style: Caption style ('professional', 'enthusiastic', 'technical')\n",
        "        platform: Target platform ('linkedin', 'twitter', 'instagram', 'portfolio')\n",
        "        include_skills: Whether to include skills in caption\n",
        "        custom_message: Custom opening message\n",
        "    \n",
        "    Returns:\n",
        "        Dict with analysis, captions, and metadata\n",
        "    \"\"\"\n",
        "    print(\"üîç Processing certificate...\")\n",
        "    \n",
        "    # Process file\n",
        "    result = file_processor.process_file(file_input, filename)\n",
        "    \n",
        "    if 'error' in result:\n",
        "        return result\n",
        "    \n",
        "    analysis = result['analysis']\n",
        "    \n",
        "    print(\"üìä Generating captions...\")\n",
        "    \n",
        "    # Generate captions for all platforms\n",
        "    captions = {}\n",
        "    for platform_name in ['linkedin', 'twitter', 'instagram', 'portfolio']:\n",
        "        captions[platform_name] = caption_generator.generate_caption(\n",
        "            analysis, style, platform_name, include_skills, custom_message if platform_name == platform else \"\"\n",
        "        )\n",
        "    \n",
        "    # Generate hashtags\n",
        "    hashtags = caption_generator.generate_hashtags(analysis, platform)\n",
        "    \n",
        "    return {\n",
        "        'success': True,\n",
        "        'analysis': asdict(analysis),\n",
        "        'captions': captions,\n",
        "        'hashtags': hashtags,\n",
        "        'primary_caption': captions[platform],\n",
        "        'extraction_info': result['extraction_info'],\n",
        "        'raw_text': result['raw_text'][:500] + \"...\" if len(result['raw_text']) > 500 else result['raw_text']\n",
        "    }\n",
        "\n",
        "# Google Colab Interface\n",
        "def upload_and_process_colab(style: str = \"professional\", platform: str = \"linkedin\", \n",
        "                           include_skills: bool = True, custom_message: str = \"\"):\n",
        "    \"\"\"Google Colab file upload interface\"\"\"\n",
        "    if not COLAB_ENV:\n",
        "        print(\"‚ùå This function is only available in Google Colab\")\n",
        "        return None\n",
        "    \n",
        "    print(\"üì§ Please upload your certificate file (PDF, JPG, PNG, etc.):\")\n",
        "    uploaded = colab_files.upload()\n",
        "    \n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No file uploaded!\")\n",
        "        return None\n",
        "    \n",
        "    filename = list(uploaded.keys())[0]\n",
        "    file_content = uploaded[filename]\n",
        "    \n",
        "    print(f\"üîÑ Processing: {filename}\")\n",
        "    return process_certificate_advanced(file_content, filename, style, platform, include_skills, custom_message)\n",
        "\n",
        "# Local File Interface\n",
        "def process_local_file(file_path: str, style: str = \"professional\", platform: str = \"linkedin\",\n",
        "                      include_skills: bool = True, custom_message: str = \"\"):\n",
        "    \"\"\"Process local file\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"‚ùå File not found: {file_path}\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"üîÑ Processing local file: {file_path}\")\n",
        "    return process_certificate_advanced(file_path, style=style, platform=platform, \n",
        "                                      include_skills=include_skills, custom_message=custom_message)\n",
        "\n",
        "# URL Interface\n",
        "def process_url(url: str, style: str = \"professional\", platform: str = \"linkedin\",\n",
        "               include_skills: bool = True, custom_message: str = \"\"):\n",
        "    \"\"\"Process certificate from URL\"\"\"\n",
        "    print(f\"üåê Processing URL: {url}\")\n",
        "    return process_certificate_advanced(url, style=style, platform=platform,\n",
        "                                      include_skills=include_skills, custom_message=custom_message)\n",
        "\n",
        "# Manual Text Input (Fallback)\n",
        "def process_manual_text(text: str, title: str = \"\", organization: str = \"\",\n",
        "                       style: str = \"professional\", platform: str = \"linkedin\",\n",
        "                       include_skills: bool = True, custom_message: str = \"\"):\n",
        "    \"\"\"Process manually entered text (fallback option)\"\"\"\n",
        "    print(\"üìù Processing manual text input...\")\n",
        "    \n",
        "    # Create manual analysis\n",
        "    analysis = CertificateAnalysis()\n",
        "    analysis.title = title or \"Professional Development Program\"\n",
        "    analysis.organization = organization\n",
        "    analysis.completion_status = \"completed\"\n",
        "    analysis.certificate_type = \"course\"\n",
        "    analysis.confidence_score = 0.9\n",
        "    analysis.industry = analyzer.detect_industry(text + \" \" + title + \" \" + organization)\n",
        "    \n",
        "    # Extract skills from text\n",
        "    analysis.skills_covered = analyzer._extract_skills_advanced(text + \" \" + title)\n",
        "    \n",
        "    # Generate captions\n",
        "    captions = {}\n",
        "    for platform_name in ['linkedin', 'twitter', 'instagram', 'portfolio']:\n",
        "        captions[platform_name] = caption_generator.generate_caption(\n",
        "            analysis, style, platform_name, include_skills, custom_message if platform_name == platform else \"\"\n",
        "        )\n",
        "    \n",
        "    hashtags = caption_generator.generate_hashtags(analysis, platform)\n",
        "    \n",
        "    return {\n",
        "        'success': True,\n",
        "        'analysis': asdict(analysis),\n",
        "        'captions': captions,\n",
        "        'hashtags': hashtags,\n",
        "        'primary_caption': captions[platform],\n",
        "        'manual_input': True\n",
        "    }\n",
        "\n",
        "# Streamlit Interface (if available)\n",
        "def create_streamlit_app():\n",
        "    \"\"\"Create Streamlit web interface\"\"\"\n",
        "    if not STREAMLIT_AVAILABLE:\n",
        "        print(\"‚ùå Streamlit not available. Install with: pip install streamlit\")\n",
        "        return None\n",
        "    \n",
        "    st.title(\"üéì Enhanced Certificate Caption Generator\")\n",
        "    st.write(\"Generate professional social media captions from your certificates!\")\n",
        "    \n",
        "    # Sidebar options\n",
        "    st.sidebar.header(\"Options\")\n",
        "    style = st.sidebar.selectbox(\"Caption Style\", [\"professional\", \"enthusiastic\", \"technical\"])\n",
        "    platform = st.sidebar.selectbox(\"Platform\", [\"linkedin\", \"twitter\", \"instagram\", \"portfolio\"])\n",
        "    include_skills = st.sidebar.checkbox(\"Include Skills\", value=True)\n",
        "    custom_message = st.sidebar.text_area(\"Custom Opening Message (optional)\")\n",
        "    \n",
        "    # File upload\n",
        "    uploaded_file = st.file_uploader(\"Upload Certificate\", type=['pdf', 'png', 'jpg', 'jpeg'])\n",
        "    \n",
        "    # URL input\n",
        "    url_input = st.text_input(\"Or enter certificate URL:\")\n",
        "    \n",
        "    # Manual input\n",
        "    with st.expander(\"Manual Input (Fallback)\"):\n",
        "        manual_text = st.text_area(\"Certificate Text\")\n",
        "        manual_title = st.text_input(\"Certificate Title\")\n",
        "        manual_org = st.text_input(\"Organization\")\n",
        "    \n",
        "    if st.button(\"Generate Caption\"):\n",
        "        result = None\n",
        "        \n",
        "        if uploaded_file:\n",
        "            file_bytes = uploaded_file.read()\n",
        "            result = process_certificate_advanced(file_bytes, uploaded_file.name, style, platform, include_skills, custom_message)\n",
        "        elif url_input:\n",
        "            result = process_url(url_input, style, platform, include_skills, custom_message)\n",
        "        elif manual_text:\n",
        "            result = process_manual_text(manual_text, manual_title, manual_org, style, platform, include_skills, custom_message)\n",
        "        \n",
        "        if result and result.get('success'):\n",
        "            st.success(\"‚úÖ Caption generated successfully!\")\n",
        "            \n",
        "            # Display analysis\n",
        "            with st.expander(\"üìä Certificate Analysis\"):\n",
        "                analysis = result['analysis']\n",
        "                st.write(f\"**Title:** {analysis['title']}\")\n",
        "                st.write(f\"**Organization:** {analysis['organization']}\")\n",
        "                st.write(f\"**Industry:** {analysis['industry']}\")\n",
        "                st.write(f\"**Skills:** {', '.join(analysis['skills_covered'])}\")\n",
        "                st.write(f\"**Confidence:** {analysis['confidence_score']:.2%}\")\n",
        "            \n",
        "            # Display captions\n",
        "            st.subheader(f\"üìù {platform.title()} Caption\")\n",
        "            st.text_area(\"Copy this caption:\", result['primary_caption'], height=200)\n",
        "            \n",
        "            # Other platform previews\n",
        "            with st.expander(\"üåê Other Platform Previews\"):\n",
        "                for p, caption in result['captions'].items():\n",
        "                    if p != platform:\n",
        "                        st.subheader(f\"{p.title()} Version\")\n",
        "                        st.text_area(f\"{p}_caption\", caption, height=150, key=f\"{p}_preview\")\n",
        "        \n",
        "        elif result:\n",
        "            st.error(f\"‚ùå Error: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "# Gradio Interface (if available)\n",
        "def create_gradio_app():\n",
        "    \"\"\"Create Gradio web interface\"\"\"\n",
        "    if not GRADIO_AVAILABLE:\n",
        "        print(\"‚ùå Gradio not available. Install with: pip install gradio\")\n",
        "        return None\n",
        "    \n",
        "    def process_for_gradio(file, url, manual_text, manual_title, manual_org, style, platform, include_skills, custom_message):\n",
        "        if file:\n",
        "            result = process_certificate_advanced(file, style=style, platform=platform, include_skills=include_skills, custom_message=custom_message)\n",
        "        elif url:\n",
        "            result = process_url(url, style, platform, include_skills, custom_message)\n",
        "        elif manual_text:\n",
        "            result = process_manual_text(manual_text, manual_title, manual_org, style, platform, include_skills, custom_message)\n",
        "        else:\n",
        "            return \"Please provide a file, URL, or manual text input.\", \"\", \"\"\n",
        "        \n",
        "        if result and result.get('success'):\n",
        "            analysis_text = f\"\"\"\n",
        "**Analysis Results:**\n",
        "- Title: {result['analysis']['title']}\n",
        "- Organization: {result['analysis']['organization']}\n",
        "- Industry: {result['analysis']['industry']}\n",
        "- Skills: {', '.join(result['analysis']['skills_covered'])}\n",
        "- Confidence: {result['analysis']['confidence_score']:.2%}\n",
        "            \"\"\"\n",
        "            return result['primary_caption'], analysis_text, f\"Hashtags: {' '.join(result['hashtags'])}\"\n",
        "        else:\n",
        "            return f\"Error: {result.get('error', 'Unknown error')}\", \"\", \"\"\n",
        "    \n",
        "    iface = gr.Interface(\n",
        "        fn=process_for_gradio,\n",
        "        inputs=[\n",
        "            gr.File(label=\"Upload Certificate\"),\n",
        "            gr.Textbox(label=\"Certificate URL\"),\n",
        "            gr.Textbox(label=\"Manual Text Input\", lines=3),\n",
        "            gr.Textbox(label=\"Certificate Title\"),\n",
        "            gr.Textbox(label=\"Organization\"),\n",
        "            gr.Dropdown([\"professional\", \"enthusiastic\", \"technical\"], label=\"Style\"),\n",
        "            gr.Dropdown([\"linkedin\", \"twitter\", \"instagram\", \"portfolio\"], label=\"Platform\"),\n",
        "            gr.Checkbox(label=\"Include Skills\", value=True),\n",
        "            gr.Textbox(label=\"Custom Message\", lines=2)\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Textbox(label=\"Generated Caption\", lines=10),\n",
        "            gr.Textbox(label=\"Analysis\"),\n",
        "            gr.Textbox(label=\"Hashtags\")\n",
        "        ],\n",
        "        title=\"üéì Enhanced Certificate Caption Generator\",\n",
        "        description=\"Upload a certificate or enter details to generate professional social media captions!\"\n",
        "    )\n",
        "    \n",
        "    return iface\n",
        "\n",
        "# Display results function\n",
        "def display_results(result: Dict):\n",
        "    \"\"\"Display results in a formatted way\"\"\"\n",
        "    if not result or not result.get('success'):\n",
        "        print(f\"‚ùå Error: {result.get('error', 'Unknown error') if result else 'No result'}\")\n",
        "        return\n",
        "    \n",
        "    analysis = result['analysis']\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"‚úÖ CERTIFICATE ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(f\"\\nüìä CERTIFICATE DETAILS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"üéØ Title: {analysis['title']}\")\n",
        "    print(f\"üè¢ Organization: {analysis['organization']}\")\n",
        "    print(f\"üë§ Recipient: {analysis['recipient_name']}\")\n",
        "    print(f\"üè≠ Industry: {analysis['industry']}\")\n",
        "    print(f\"üìö Type: {analysis['certificate_type'].title()}\")\n",
        "    print(f\"‚úÖ Status: {analysis['completion_status'].title()}\")\n",
        "    print(f\"‚è±Ô∏è Duration: {analysis['duration'] or 'Not specified'}\")\n",
        "    print(f\"üìÖ Date: {analysis['date_issued'] or 'Not specified'}\")\n",
        "    print(f\"üîß Skills: {', '.join(analysis['skills_covered']) if analysis['skills_covered'] else 'Not detected'}\")\n",
        "    print(f\"üìà Confidence: {analysis['confidence_score']:.1%}\")\n",
        "    \n",
        "    print(f\"\\nüîç EXTRACTION INFO:\")\n",
        "    print(\"-\" * 40)\n",
        "    extraction = result['extraction_info']\n",
        "    print(f\"Method: {extraction.get('method', extraction.get('engine_used', 'Unknown'))}\")\n",
        "    print(f\"Confidence: {extraction.get('confidence', 0):.1%}\")\n",
        "    \n",
        "    print(f\"\\nüìù GENERATED CAPTIONS:\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for platform, caption in result['captions'].items():\n",
        "        print(f\"\\nüåê {platform.upper()} VERSION:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(caption)\n",
        "        print(f\"\\nCharacters: {len(caption)}\")\n",
        "    \n",
        "    print(f\"\\nüè∑Ô∏è HASHTAGS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\" \".join(result['hashtags']))\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìã READY TO COPY AND PASTE!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "print(\"üöÄ Enhanced Certificate Caption Generator is ready!\")\n",
        "print(\"\\nAvailable functions:\")\n",
        "print(\"üì± For Google Colab: upload_and_process_colab()\")\n",
        "print(\"üíª For local files: process_local_file('path/to/file')\")\n",
        "print(\"üåê For URLs: process_url('https://example.com/cert.pdf')\")\n",
        "print(\"üìù For manual input: process_manual_text('certificate text')\")\n",
        "if STREAMLIT_AVAILABLE:\n",
        "    print(\"üñ•Ô∏è For Streamlit app: create_streamlit_app()\")\n",
        "if GRADIO_AVAILABLE:\n",
        "    print(\"üé® For Gradio app: create_gradio_app()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick Start Functions and Examples\n",
        "\n",
        "def quick_start():\n",
        "    \"\"\"Quick start guide and demo\"\"\"\n",
        "    print(\"üöÄ ENHANCED CERTIFICATE CAPTION GENERATOR\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"\\n‚ú® FEATURES:\")\n",
        "    print(\"‚Ä¢ Multiple OCR engines for better text extraction\")\n",
        "    print(\"‚Ä¢ 3 caption styles: Professional, Enthusiastic, Technical\")\n",
        "    print(\"‚Ä¢ 4 platforms: LinkedIn, Twitter, Instagram, Portfolio\")\n",
        "    print(\"‚Ä¢ Industry-specific hashtags\")\n",
        "    print(\"‚Ä¢ Support for files, URLs, and manual input\")\n",
        "    print(\"‚Ä¢ Works in Google Colab, Jupyter, and standalone\")\n",
        "    \n",
        "    print(\"\\nüéØ QUICK START OPTIONS:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    if COLAB_ENV:\n",
        "        print(\"üì± Google Colab - Upload file:\")\n",
        "        print(\"   result = upload_and_process_colab()\")\n",
        "        print(\"   display_results(result)\")\n",
        "    else:\n",
        "        print(\"üíª Local Environment:\")\n",
        "        print(\"   # Process local file\")\n",
        "        print(\"   result = process_local_file('path/to/certificate.pdf')\")\n",
        "        print(\"   display_results(result)\")\n",
        "        print()\n",
        "        print(\"   # Process from URL\")\n",
        "        print(\"   result = process_url('https://example.com/cert.pdf')\")\n",
        "        print(\"   display_results(result)\")\n",
        "    \n",
        "    print(\"\\nüìù Manual Input (Fallback):\")\n",
        "    print(\"   result = process_manual_text(\")\n",
        "    print(\"       text='Course completion certificate...',\")\n",
        "    print(\"       title='Data Science Bootcamp',\")\n",
        "    print(\"       organization='Tech Academy'\")\n",
        "    print(\"   )\")\n",
        "    print(\"   display_results(result)\")\n",
        "    \n",
        "    print(\"\\nüé® Customization Options:\")\n",
        "    print(\"   style: 'professional', 'enthusiastic', 'technical'\")\n",
        "    print(\"   platform: 'linkedin', 'twitter', 'instagram', 'portfolio'\")\n",
        "    print(\"   include_skills: True/False\")\n",
        "    print(\"   custom_message: 'Your custom opening message'\")\n",
        "    \n",
        "    if STREAMLIT_AVAILABLE:\n",
        "        print(\"\\nüñ•Ô∏è Web Interface (Streamlit):\")\n",
        "        print(\"   app = create_streamlit_app()\")\n",
        "        print(\"   # Then run: streamlit run your_script.py\")\n",
        "    \n",
        "    if GRADIO_AVAILABLE:\n",
        "        print(\"\\nüé® Web Interface (Gradio):\")\n",
        "        print(\"   app = create_gradio_app()\")\n",
        "        print(\"   app.launch()\")\n",
        "\n",
        "def demo_with_sample():\n",
        "    \"\"\"Demo with sample certificate text\"\"\"\n",
        "    sample_text = '''\n",
        "    Certificate of Completion\n",
        "    \n",
        "    This certifies that John Doe has successfully completed the\n",
        "    Data Science and Machine Learning Bootcamp\n",
        "    \n",
        "    Topics covered:\n",
        "    Python Programming, Statistics, Machine Learning, Data Visualization,\n",
        "    Deep Learning, Natural Language Processing, SQL, Git\n",
        "    \n",
        "    Duration: 12 weeks\n",
        "    Issued by: TechAcademy Institute\n",
        "    Date: October 2024\n",
        "    '''\n",
        "    \n",
        "    print(\"üéØ DEMO: Processing sample certificate...\")\n",
        "    \n",
        "    result = process_manual_text(\n",
        "        text=sample_text,\n",
        "        title=\"Data Science and Machine Learning Bootcamp\",\n",
        "        organization=\"TechAcademy Institute\",\n",
        "        style=\"enthusiastic\",\n",
        "        platform=\"linkedin\"\n",
        "    )\n",
        "    \n",
        "    if result:\n",
        "        display_results(result)\n",
        "    else:\n",
        "        print(\"‚ùå Demo failed\")\n",
        "\n",
        "def test_all_styles():\n",
        "    \"\"\"Test all caption styles with sample data\"\"\"\n",
        "    sample_analysis = CertificateAnalysis(\n",
        "        title=\"Advanced Python Programming\",\n",
        "        organization=\"Code Institute\",\n",
        "        certificate_type=\"course\",\n",
        "        skills_covered=[\"Python\", \"Object-Oriented Programming\", \"API Development\", \"Testing\"],\n",
        "        industry=\"technology\",\n",
        "        confidence_score=0.95\n",
        "    )\n",
        "    \n",
        "    print(\"üé® TESTING ALL CAPTION STYLES:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    styles = [\"professional\", \"enthusiastic\", \"technical\"]\n",
        "    \n",
        "    for style in styles:\n",
        "        print(f\"\\nüìù {style.upper()} STYLE:\")\n",
        "        print(\"-\" * 30)\n",
        "        caption = caption_generator.generate_caption(sample_analysis, style, \"linkedin\")\n",
        "        print(caption)\n",
        "        print(f\"\\nLength: {len(caption)} characters\")\n",
        "\n",
        "# Environment-specific startup\n",
        "def auto_start():\n",
        "    \"\"\"Automatically start the best interface for current environment\"\"\"\n",
        "    if COLAB_ENV:\n",
        "        print(\"üî• AUTO-STARTING GOOGLE COLAB INTERFACE...\")\n",
        "        quick_start()\n",
        "        print(\"\\nüé¨ To begin, run: upload_and_process_colab()\")\n",
        "        \n",
        "    elif STREAMLIT_AVAILABLE:\n",
        "        print(\"üî• STREAMLIT DETECTED!\")\n",
        "        print(\"Run this to start web interface:\")\n",
        "        print(\"create_streamlit_app()\")\n",
        "        \n",
        "    elif GRADIO_AVAILABLE:\n",
        "        print(\"üî• GRADIO DETECTED!\")\n",
        "        print(\"Run this to start web interface:\")\n",
        "        print(\"app = create_gradio_app()\")\n",
        "        print(\"app.launch()\")\n",
        "        \n",
        "    else:\n",
        "        print(\"üî• LOCAL ENVIRONMENT DETECTED\")\n",
        "        quick_start()\n",
        "\n",
        "# Utility functions\n",
        "def save_caption_to_file(caption: str, filename: str = \"\"):\n",
        "    \"\"\"Save generated caption to a text file\"\"\"\n",
        "    if not filename:\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"linkedin_caption_{timestamp}.txt\"\n",
        "    \n",
        "    try:\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(caption)\n",
        "        print(f\"‚úÖ Caption saved to: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to save caption: {e}\")\n",
        "\n",
        "def analyze_caption_metrics(caption: str, platform: str = \"linkedin\") -> Dict:\n",
        "    \"\"\"Analyze caption metrics for different platforms\"\"\"\n",
        "    metrics = {\n",
        "        'character_count': len(caption),\n",
        "        'word_count': len(caption.split()),\n",
        "        'hashtag_count': len(re.findall(r'#\\w+', caption)),\n",
        "        'emoji_count': len(re.findall(r'[üòÄ-üôèüåÄ-üóøüöÄ-üõø‚≠ê-‚≠ï]', caption))\n",
        "    }\n",
        "    \n",
        "    # Platform-specific limits\n",
        "    limits = {\n",
        "        'linkedin': {'max_chars': 3000, 'recommended_chars': 1300},\n",
        "        'twitter': {'max_chars': 280, 'recommended_chars': 240},\n",
        "        'instagram': {'max_chars': 2200, 'recommended_chars': 1500},\n",
        "        'portfolio': {'max_chars': 1000, 'recommended_chars': 500}\n",
        "    }\n",
        "    \n",
        "    platform_limits = limits.get(platform, limits['linkedin'])\n",
        "    metrics['within_limit'] = metrics['character_count'] <= platform_limits['max_chars']\n",
        "    metrics['optimal_length'] = metrics['character_count'] <= platform_limits['recommended_chars']\n",
        "    metrics['platform'] = platform\n",
        "    metrics['limits'] = platform_limits\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def print_metrics(caption: str, platform: str = \"linkedin\"):\n",
        "    \"\"\"Print formatted caption metrics\"\"\"\n",
        "    metrics = analyze_caption_metrics(caption, platform)\n",
        "    \n",
        "    print(f\"\\nüìä CAPTION METRICS ({platform.upper()}):\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Characters: {metrics['character_count']}\")\n",
        "    print(f\"Words: {metrics['word_count']}\")\n",
        "    print(f\"Hashtags: {metrics['hashtag_count']}\")\n",
        "    print(f\"Emojis: {metrics['emoji_count']}\")\n",
        "    print(f\"Within limit: {'‚úÖ' if metrics['within_limit'] else '‚ùå'}\")\n",
        "    print(f\"Optimal length: {'‚úÖ' if metrics['optimal_length'] else '‚ö†Ô∏è'}\")\n",
        "\n",
        "# Auto-run quick start\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ ENHANCED CERTIFICATE CAPTION GENERATOR LOADED!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "quick_start()\n",
        "\n",
        "print(\"\\nüöÄ Ready to process your certificates!\")\n",
        "print(\"Type quick_start() for help, or demo_with_sample() for a demo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo the Enhanced System\n",
        "print(\"üé¨ DEMONSTRATING THE ENHANCED CERTIFICATE CAPTION GENERATOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test with sample certificate data using the test_all_styles function\n",
        "print(\"üé® TESTING ALL CAPTION STYLES:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "sample_analysis = CertificateAnalysis(\n",
        "    title=\"Advanced Python Programming Bootcamp\",\n",
        "    organization=\"Code Institute\",\n",
        "    certificate_type=\"course\",\n",
        "    skills_covered=[\"Python\", \"Object-Oriented Programming\", \"API Development\", \"Testing\", \"Data Analysis\"],\n",
        "    industry=\"technology\",\n",
        "    confidence_score=0.95,\n",
        "    completion_status=\"completed\"\n",
        ")\n",
        "\n",
        "styles = [\"professional\", \"enthusiastic\", \"technical\"]\n",
        "\n",
        "for style in styles:\n",
        "    print(f\"\\nüìù {style.upper()} STYLE:\")\n",
        "    print(\"-\" * 40)\n",
        "    caption = caption_generator.generate_caption(sample_analysis, style, \"linkedin\", include_skills=True)\n",
        "    print(caption)\n",
        "    print(f\"\\nüìä Length: {len(caption)} characters\")\n",
        "    \n",
        "    # Show hashtags for this style\n",
        "    hashtags = caption_generator.generate_hashtags(sample_analysis, \"linkedin\")\n",
        "    print(f\"üè∑Ô∏è Hashtags: {' '.join(hashtags[:5])}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ DEMO COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüöÄ TO USE THE ENHANCED SYSTEM:\")\n",
        "print(\"‚Ä¢ For local files: process_local_file('path/to/certificate.pdf')\")\n",
        "print(\"‚Ä¢ For URLs: process_url('https://example.com/cert.pdf')\")\n",
        "print(\"‚Ä¢ For manual input: process_manual_text('your certificate text', 'title', 'organization')\")\n",
        "print(\"‚Ä¢ For web interface: create_streamlit_app() or create_gradio_app()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and Launch Web Interface (Optional)\n",
        "\n",
        "print(\"üñ•Ô∏è WEB INTERFACE OPTIONS:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Option 1: Gradio Interface (Recommended for quick demos)\n",
        "print(\"1Ô∏è‚É£ GRADIO INTERFACE (Recommended)\")\n",
        "print(\"   Simple, fast, and works great for demos\")\n",
        "print(\"   Uncomment the lines below to launch:\")\n",
        "print()\n",
        "print(\"   # app = create_gradio_app()\")\n",
        "print(\"   # app.launch(share=True)  # share=True creates public link\")\n",
        "print()\n",
        "\n",
        "# Option 2: Streamlit Interface (Better for production)\n",
        "print(\"2Ô∏è‚É£ STREAMLIT INTERFACE (Production-ready)\")\n",
        "print(\"   More features, better for hosting\")\n",
        "print(\"   Save this notebook as a .py file and run:\")\n",
        "print(\"   streamlit run your_script.py\")\n",
        "print()\n",
        "\n",
        "# Quick example of processing a file\n",
        "print(\"3Ô∏è‚É£ COMMAND LINE USAGE EXAMPLE:\")\n",
        "print(\"   # Process a local certificate file\")\n",
        "print(\"   # result = process_local_file('certificate.pdf', style='enthusiastic', platform='linkedin')\")\n",
        "print(\"   # display_results(result)\")\n",
        "\n",
        "print(\"\\nüéØ FEATURES SUMMARY:\")\n",
        "print(\"‚úÖ Multi-platform support (Google Colab, Jupyter, VS Code, Standalone)\")\n",
        "print(\"‚úÖ Multiple OCR engines (PyTesseract + EasyOCR)\")\n",
        "print(\"‚úÖ 3 caption styles (Professional, Enthusiastic, Technical)\")\n",
        "print(\"‚úÖ 4 output formats (LinkedIn, Twitter, Instagram, Portfolio)\")\n",
        "print(\"‚úÖ Industry-specific hashtags\")\n",
        "print(\"‚úÖ Support for files, URLs, and manual input\")\n",
        "print(\"‚úÖ Advanced image preprocessing\")\n",
        "print(\"‚úÖ Web interfaces (Streamlit & Gradio)\")\n",
        "print(\"‚úÖ Enhanced error handling and fallbacks\")\n",
        "\n",
        "print(\"\\nüöÄ Your enhanced certificate caption generator is ready to use!\")\n",
        "print(\"   Choose your preferred method and start generating professional captions! üéâ\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
